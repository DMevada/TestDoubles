# Implementation Details 

## Tech Stack

1. NodeJS: Server side Javascript framework.
2. HapiJS: Web framework for building RESTful APIs in Javascript.
3. log4js: A NodeJS logging library. 
4. Mocha: Testing framework for JavaScript.
5. Chai: Assertion library.

## Request Lifecycle

When a request is first made by the client, it is handled by the HapiJS router. The routes are defined in the routes file, inside src/. The routes file is structured such that each API is handled by a separate controller. The routes file also has access to the handlers of every API. Each API is uniquely defined by the following:

1. method (GET, POST, PUT, DELETE, etc.)
2. path (/, /testdoubles, /testdoubles/{testDoubleName}, etc.)
3. handler (A function that resides in a separate controller file that contains the logic to handle the request.)

The ratio of routes to controllers to tests is 1:1:1. This means that each route defined in the routes file corresponds to a single controller, which in turn corresponds to a single test file. After a request is sent to the route, it is then handled by the appropriate controller. Once the controller finishes executing its logic, it will then call a specific function inside the requests file. The requests file is also inside src/, and is responsible for making all HTTP requests to the underlying Mountebank API. 

Each function in the requests file, although independent, relies on other functions as its callback. The reason callbacks are used in because Node's HTTP request methods are asynchronous. As a result, the code that is meant to be executed after the asynchronous HTTP request is made must reside in the callback function. In some functions, the callback is an anonymous function because it is easier to execute in-line. Also, all the functions that make the HTTP request in the requests.js file contain only two parameters. The first is the testDoubleDefinition, and the second is the reply object. 

It can be argued that Node's HTTP request library is verbose in comparison to other open-source libraries such as request, restify, unirest, and others which perform the same task in fewer lines of code. However, Node's standard library is used here because it is well-tested and reliable. In the test folder, Node's HTTP library is not used because its verbosity is a drawback. As a result, all tests are written using the request library to make HTTP requests to the Testdoubles API.

Once the request is handled, a reply response is sent back to the client from the Hapi webserver. If the reply object is not passed to the function in the requests.js file, an internal server error will be generated by Hapi.

## Logger and Utils

The logger.js and the utils.js file are also vital for the execution of the application. The logger contains the configuration to setup a logger object, which is then used by the utils file. Each file that imports the utils file also subsequently imports the logger. The log level is implemented by reading the NODE_ENV environment variable. If it is not set, it will be defaulted to "development". As a result, if the value of the env variable is "development" the log level will be set to debug. For all other values, the log level will be set to info. The log file is inside the logs/ folder. 

The utils file contains all the functions that are commonly used by most controllers. This includes file checking, writing to files, deleting files, and retrieving the testdouble object.

## Testdoubles (AKA TD)

Each testdouble has a testDoubleName.json file, where testDoubleName is the name of the testdouble. This file houses
the definition of the testdouble. All testdouble definitions are stored in the testdoubles/ directory.

A JSON example for a testdouble's definition file is given below.

```
{
    protocol: "http",
    name: "google",
    port: 5051,
    stubs: [
      {
        responses: [
          {
            proxy: {
              to: "http://maps.googleapis.com",
              mode: "proxyAlways",
              predicateGenerators: [{
                matches: {
                  method: true,
                  path: true,
                  query: true                   
              }
            }]
          }
        }
      ]
    }
  ]
}
```

The above example describes a testdouble that contains a proxy to the Google Maps API. 

# 12 Factor Application

A well-designed and programmed application generally follows the 12 factors standard for the SaaS model.
The TestDoubles software is evaluated for each of the 12 factors below.

1. Codebase
    - Codebase refers to having one repository in which the code is tracked. Each deployment of the code is still considered the same codebase. TestDoubles is compliant with this factor, as all code is stored in this repo.
    
2. Dependencies
    - Have all dependencies (modules or other programs that the software relies on), present in a local manner. That is, there are no dependencies on what the underlying OS provides. TestDoubles is mostly compliant with this factor. TestDoubles relies on curl as a system-wide dependency, but all other dependencies can be installed using npm install.
    
3. Config
    - Configuration in the code should never be hard-coded, but rather important values should be stored in environment variables. TestDoubles is compliant with this factor.
    
4. Backing Services

    - Each local resource or a third party resource should be treated alike, so that resources can be replaced easily if necessary in the future. TestDoubles is compliant with this factor. 

5. Build, release, run

    - The processes of building, releasing and running must be separate. TestDoubles is compliant with this factor because it has a Makefile which houses separate commands for each of the above processes. Building a docker container is done with one command, release (to DockerHub) is done with another command, and finally the run is also another command.

6. Processes

    - The execution of the software must be a single process, and also the software must be stateless. TestDoubles is not compliant with this factor.

7. Port Binding

    - The application is self-contained and incoming requests are handled by an external entity that will route the request to the specified port. TestDoubles is compliant with this factor.

8. Concurrency

    - There should be different process types and each process type should handle the necessary operation accordingly. TestDoubles is not compliant with this factor because it creates a pid file for each instance of the TestDouble.

9. Disposability

    - The application and its processes should be disposable, and they should be quick to start up. TestDoubles is compliant with this factor because it starts within seconds, and also shuts down gracefully.

10. Dev/Prod parity

    - There should be almost no distinction between the Dev and Prod environments. Builds should occur quickly and there should be no inconsistencies. TestDoubles is compliant with this factor.

11. Logs

    - Logs should be gathered in a single location for viewing and archiving. TestDoubles is compliant with this factor.

12. Admin Processes

    - Admin code should be the same as production code, and must ship with it. Dependency isolation and other factors also apply. TestDoubles is compliant with this factor.
    
# Scalability 

There are two options for scalability. The first is to embed Montebank (AKA MB) inside of TD, and the second is to separate MB from TD.
Irrespective of the option, there is always a TD registry file that maintains a lookup of the testdoubles that exist on each node. The registry file is maintained by Consul. Each instance of TD runs inside a docker container. A node can have many docker containers, and each node must also have a docker container for Registrator. Registrator is a third party service that automatically registers and deregisters a service with Consul. Consul should be on its own node, and not in a docker container. 

There are two main problems for scalability: service discovery and service registration. 

## Service Discovery

There are two possible solutions to service discovery - client side discovery and server side discovery. 
Client side discovery queries the service registry and the client uses a loadbalancing algorithm to choose the service and route accordingly.

Pros 

- Client can make its own decisions regarding routing to the correct service

Cons

- Client code must have logic to select a service, and this is an overhead because it unnecessarily combines the client with the service.


Server side service discovery relies on the loadbalancer to query the service registry and then route the client request accordingly. 

Pros 

- Client is not responsible for discovery

Con

- Need to maintain one more component

## Service Registration

There are two possible solutions for service registration: self registration and third party registration.

Self registration (and deregistration) requires the service to register with Consul, using either the Consul HTTP API or DNS API. 

Pros

- No third party application required

Cons

- Application will have to register itself


Third party registration requires another component called a service registrar to register the service. In this case, an application called Registrator can automatically register a service to Consul.

Pros

- Automatic, because the application does not have to handle the registration

Cons

- One more component dependency

## TD Registry File Structure

The TD registry file essentially contains key value pairs that map the TD host to a testdouble. If an entry doesn't exist, it means that the testdouble does not exist. The TD registry file should be updated only for the APIs shown below.

    1. POST /testdoubles
    2. PUT /testdoubles
    3. DELETE /testdoubles/{testDoubleName}
    4. DELETE /testdoubles

The existence of a testdouble is determined by whether the testdouble with provided name exists in the lookup file. 

## Embed MB inside of TD

Cons 

- Lack of control between TD and MB, because MB is embedded inside of TD.
- TD remains stateful
- Disposing of TD also disposes of MB

Pros

- There is only one registry file and that is the TD registry file. 
- All HTTP requests will be made to localhost, so there is no need to make changes to any code that makes HTTP requests.

## Separate MB from TD

Cons
    
- Code that makes HTTP requests will have to be changed to dynamically make a request to the particular host.
- tdctl file have to be changed, because MB is no longer imported. This has a cascading effect because MB and TD must be started separately.
- If MB is unavailable, it must be restarted separately from TD. 
- Requires more nodes (either physical or virtual).
- Requires one more environment variable, MB_HOST.

Pros

- TD becomes stateless, as all state is now maintained in MB, thus achieving disposability.
- Allows for greater control of TD, and with this, implemeting SIGTERM and SIGINT behavior is possible.
